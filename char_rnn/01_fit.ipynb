{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0EJMRASTG8j"
   },
   "outputs": [],
   "source": [
    "# base\n",
    "import re, pickle\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCH21BnXTG8m"
   },
   "outputs": [],
   "source": [
    "with open('data/trump_raw_text.txt', 'r', encoding='utf8') as myfile:\n",
    "    raw_text = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrigU3ZBTG8o"
   },
   "outputs": [],
   "source": [
    "def clean_text(t):\n",
    "    # to lower\n",
    "    t = t.lower()\n",
    "    # remove quotes\n",
    "    t = re.sub(r'\"@.*', '', t)\n",
    "    t = re.sub(r'^“.*”$', '', t)\n",
    "    # remove URLs\n",
    "    t = re.sub(r'https*:\\/\\/\\S*', '', t)\n",
    "    t = re.sub(r'pic\\.twitter\\.com\\/\\S*', '', t)\n",
    "    # remove \\n\n",
    "    t = re.sub('\\n', ' ', t)\n",
    "    # remove extra whitespaces\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    # replace '&amp' with 'and'\n",
    "    t = re.sub('&amp;', 'and', t)     \n",
    "    # replace abbreviations\n",
    "    t = re.sub(\"'ll\", ' will', t)\n",
    "    t = re.sub(\"won't\", 'will not', t)\n",
    "    t = re.sub(\"n't\", ' not', t) \n",
    "    # remove @mention\n",
    "    t = re.sub(r'@[A-Za-z0-9_]+', '', t) \n",
    "    # remove #tag\n",
    "    t = re.sub(r'#[A-Za-z0-9_]+', '', t) \n",
    "    # remove special characters\n",
    "    t = re.sub(r'[^a-zA-Z ]', '', t) \n",
    "    # remove multiple spaces \n",
    "    t = re.sub(\"\\s\\s+\", \" \", t) \n",
    "    return t\n",
    "\n",
    "raw_text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1591077323254,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "N9xlCGtkTG8v",
    "outputId": "2f85ef91-c3c7-43a5-9996-abc2066117b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  920369\n",
      "Total Vocab:  27\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCR3C_99TG8x"
   },
   "outputs": [],
   "source": [
    "with open('data/chars.txt', 'wb') as fp:\n",
    "    pickle.dump(chars, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vkXw6xLTG8z"
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5943,
     "status": "ok",
     "timestamp": 1591077328272,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "8CSC5N4qTG81",
    "outputId": "a08acebc-d341-4252-9272-3ff461db63f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  828242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Total Patterns: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18838,
     "status": "ok",
     "timestamp": 1591077341174,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "nyJwelaMTG83",
    "outputId": "9b0c02ae-a1e0-4d31-9d3b-d52050300986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 256)         264192    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 27)                6939      \n",
      "=================================================================\n",
      "Total params: 1,321,755\n",
      "Trainable params: 1,321,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(X_train, (len(X_train), seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(y_train)\n",
    "# define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(None, X.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256, dropout=0.2),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7361816,
     "status": "ok",
     "timestamp": 1591084684158,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "aLphD14yTG85",
    "outputId": "a9436edf-32d4-4def-9e71-094550e0306a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 745417 samples, validate on 82825 samples\n",
      "Epoch 1/100\n",
      "745417/745417 [==============================] - 264s 355us/sample - loss: 2.2960 - val_loss: 1.9190\n",
      "Epoch 2/100\n",
      "745417/745417 [==============================] - 283s 379us/sample - loss: 1.8120 - val_loss: 1.6404\n",
      "Epoch 3/100\n",
      "745417/745417 [==============================] - 260s 349us/sample - loss: 1.6480 - val_loss: 1.5333\n",
      "Epoch 4/100\n",
      "745417/745417 [==============================] - 259s 347us/sample - loss: 1.5671 - val_loss: 2.3246\n",
      "Epoch 5/100\n",
      "745417/745417 [==============================] - 281s 378us/sample - loss: 1.5056 - val_loss: 1.4921\n",
      "Epoch 6/100\n",
      "745417/745417 [==============================] - 568s 762us/sample - loss: 1.4481 - val_loss: 1.3905\n",
      "Epoch 7/100\n",
      "745417/745417 [==============================] - 252s 338us/sample - loss: 1.4131 - val_loss: 1.3619\n",
      "Epoch 8/100\n",
      "745417/745417 [==============================] - 250s 335us/sample - loss: 1.3854 - val_loss: 1.3463\n",
      "Epoch 9/100\n",
      "745417/745417 [==============================] - 248s 333us/sample - loss: 1.3626 - val_loss: 1.3404\n",
      "Epoch 10/100\n",
      "745417/745417 [==============================] - 260s 349us/sample - loss: 1.3433 - val_loss: 1.3308\n",
      "Epoch 11/100\n",
      "745417/745417 [==============================] - 271s 363us/sample - loss: 1.3270 - val_loss: 1.3407\n",
      "Epoch 12/100\n",
      "745417/745417 [==============================] - 257s 345us/sample - loss: 1.3129 - val_loss: 1.3087\n",
      "Epoch 13/100\n",
      "745417/745417 [==============================] - 247s 332us/sample - loss: 1.3013 - val_loss: 1.3081\n",
      "Epoch 14/100\n",
      "745417/745417 [==============================] - 243s 326us/sample - loss: 1.2907 - val_loss: 1.2951\n",
      "Epoch 15/100\n",
      "745417/745417 [==============================] - 248s 333us/sample - loss: 1.2820 - val_loss: 1.2982\n",
      "Epoch 16/100\n",
      "745417/745417 [==============================] - 251s 337us/sample - loss: 1.3543 - val_loss: 1.3014\n",
      "Epoch 17/100\n",
      "745417/745417 [==============================] - 248s 333us/sample - loss: 1.2695 - val_loss: 1.2888\n",
      "Epoch 18/100\n",
      "745417/745417 [==============================] - 249s 334us/sample - loss: 1.3153 - val_loss: 1.2817\n",
      "Epoch 19/100\n",
      "745417/745417 [==============================] - 252s 338us/sample - loss: 1.2684 - val_loss: 1.2712\n",
      "Epoch 20/100\n",
      "745417/745417 [==============================] - 254s 340us/sample - loss: 1.2585 - val_loss: 1.2760\n",
      "Epoch 21/100\n",
      "745417/745417 [==============================] - 257s 345us/sample - loss: 1.2455 - val_loss: 1.2691\n",
      "Epoch 22/100\n",
      "745417/745417 [==============================] - 260s 348us/sample - loss: 1.8760 - val_loss: 1.2833\n",
      "Epoch 23/100\n",
      "745417/745417 [==============================] - 261s 350us/sample - loss: 1.2438 - val_loss: 1.2694\n",
      "Epoch 24/100\n",
      "745417/745417 [==============================] - 305s 409us/sample - loss: 1.4213 - val_loss: 1.2622\n",
      "Epoch 25/100\n",
      "745417/745417 [==============================] - 341s 457us/sample - loss: 1.2875 - val_loss: 1.2664\n",
      "Epoch 26/100\n",
      "745417/745417 [==============================] - 327s 439us/sample - loss: 2.0456 - val_loss: 1.2806\n",
      "Epoch 27/100\n",
      "745417/745417 [==============================] - 318s 427us/sample - loss: 1.2281 - val_loss: 1.2660\n",
      "Epoch 28/100\n",
      "745417/745417 [==============================] - 318s 427us/sample - loss: 1.2248 - val_loss: 1.2604\n",
      "Epoch 29/100\n",
      "745417/745417 [==============================] - 342s 459us/sample - loss: 1.2466 - val_loss: 1.2657\n",
      "Epoch 30/100\n",
      "745417/745417 [==============================] - 1048s 1ms/sample - loss: 4.9170 - val_loss: 1.2775\n",
      "Epoch 31/100\n",
      "745417/745417 [==============================] - 281s 378us/sample - loss: 1.2399 - val_loss: 1.3134\n",
      "Epoch 32/100\n",
      "745417/745417 [==============================] - 334s 448us/sample - loss: 6.6250 - val_loss: 1.7292\n",
      "Epoch 33/100\n",
      "745417/745417 [==============================] - 321s 431us/sample - loss: 1.7004 - val_loss: 1.6563\n",
      "Epoch 34/100\n",
      "745417/745417 [==============================] - 283s 379us/sample - loss: 1.6318 - val_loss: 1.5443\n",
      "Epoch 35/100\n",
      "738432/745417 [============================>.] - ETA: 2s - loss: 1.6042"
     ]
    }
   ],
   "source": [
    "early_stop = [EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')]\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=100, batch_size=128, callbacks=early_stop, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06AA1-5nTG86"
   },
   "outputs": [],
   "source": [
    "model.save('models/trump_model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
