{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0EJMRASTG8j"
   },
   "outputs": [],
   "source": [
    "# base\n",
    "import re, pickle\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCH21BnXTG8m"
   },
   "outputs": [],
   "source": [
    "with open('data/trump_raw_text.txt', 'r', encoding='utf8') as myfile:\n",
    "    raw_text = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrigU3ZBTG8o"
   },
   "outputs": [],
   "source": [
    "def clean_text(t):\n",
    "    # to lower\n",
    "    t = t.lower()\n",
    "    # remove quotes\n",
    "    t = re.sub(r'\"@.*', '', t)\n",
    "    t = re.sub(r'^“.*”$', '', t)\n",
    "    # remove URLs\n",
    "    t = re.sub(r'https*:\\/\\/\\S*', '', t)\n",
    "    t = re.sub(r'pic\\.twitter\\.com\\/\\S*', '', t)\n",
    "    # remove \\n\n",
    "    t = re.sub('\\n', ' ', t)\n",
    "    # remove extra whitespaces\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    # replace '&amp' with 'and'\n",
    "    t = re.sub('&amp;', 'and', t)     \n",
    "    # replace abbreviations\n",
    "    t = re.sub(\"'ll\", ' will', t)\n",
    "    t = re.sub(\"won't\", 'will not', t)\n",
    "    t = re.sub(\"n't\", ' not', t) \n",
    "    # remove @mention\n",
    "    t = re.sub(r'@[A-Za-z0-9_]+', '', t) \n",
    "    # remove #tag\n",
    "    t = re.sub(r'#[A-Za-z0-9_]+', '', t) \n",
    "    # remove special characters\n",
    "    t = re.sub(r'[^a-zA-Z ]', '', t) \n",
    "    # remove multiple spaces \n",
    "    t = re.sub(\"\\s\\s+\", \" \", t) \n",
    "    return t\n",
    "\n",
    "raw_text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1591077323254,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "N9xlCGtkTG8v",
    "outputId": "2f85ef91-c3c7-43a5-9996-abc2066117b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  920369\n",
      "Total Vocab:  27\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCR3C_99TG8x"
   },
   "outputs": [],
   "source": [
    "with open('data/chars.txt', 'wb') as fp:\n",
    "    pickle.dump(chars, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vkXw6xLTG8z"
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5943,
     "status": "ok",
     "timestamp": 1591077328272,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "8CSC5N4qTG81",
    "outputId": "a08acebc-d341-4252-9272-3ff461db63f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  828242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Total Patterns: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18838,
     "status": "ok",
     "timestamp": 1591077341174,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "nyJwelaMTG83",
    "outputId": "9b0c02ae-a1e0-4d31-9d3b-d52050300986"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(X_train, (len(X_train), seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(y_train)\n",
    "# define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(256, dropout=0.2, input_shape=(None, X.shape[2]), return_sequences=True),\n",
    "    LSTM(256, dropout=0.2, return_sequences=True),\n",
    "    LSTM(256, dropout=0.2),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7361816,
     "status": "ok",
     "timestamp": 1591084684158,
     "user": {
      "displayName": "Xabier Etxezarreta Argarate",
      "photoUrl": "",
      "userId": "15184980590702807715"
     },
     "user_tz": -120
    },
    "id": "aLphD14yTG85",
    "outputId": "a9436edf-32d4-4def-9e71-094550e0306a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 745417 samples, validate on 82825 samples\n",
      "Epoch 1/100\n",
      "745417/745417 [==============================] - 324s 435us/sample - loss: 2.2730 - val_loss: 1.8159\n",
      "Epoch 2/100\n",
      "745417/745417 [==============================] - 317s 425us/sample - loss: 1.8135 - val_loss: 1.6243\n",
      "Epoch 3/100\n",
      "745417/745417 [==============================] - 312s 419us/sample - loss: 1.6656 - val_loss: 1.5120\n",
      "Epoch 4/100\n",
      "745417/745417 [==============================] - 293s 393us/sample - loss: 1.5815 - val_loss: 1.4399\n",
      "Epoch 5/100\n",
      "745417/745417 [==============================] - 328s 440us/sample - loss: 1.5252 - val_loss: 1.5414\n",
      "Epoch 6/100\n",
      "745417/745417 [==============================] - 327s 439us/sample - loss: 1.4835 - val_loss: 1.3894\n",
      "Epoch 7/100\n",
      "745417/745417 [==============================] - 328s 440us/sample - loss: 1.4501 - val_loss: 1.3439\n",
      "Epoch 8/100\n",
      "745417/745417 [==============================] - 315s 423us/sample - loss: 1.4247 - val_loss: 1.3331\n",
      "Epoch 9/100\n",
      "745417/745417 [==============================] - 314s 421us/sample - loss: 1.4030 - val_loss: 1.3136\n",
      "Epoch 10/100\n",
      "745417/745417 [==============================] - 317s 425us/sample - loss: 1.3842 - val_loss: 1.2942\n",
      "Epoch 11/100\n",
      "745417/745417 [==============================] - 318s 427us/sample - loss: 1.3692 - val_loss: 1.2913\n",
      "Epoch 12/100\n",
      "745417/745417 [==============================] - 311s 417us/sample - loss: 1.3563 - val_loss: 1.2793\n",
      "Epoch 13/100\n",
      "745417/745417 [==============================] - 318s 426us/sample - loss: 1.3445 - val_loss: 1.2757\n",
      "Epoch 14/100\n",
      "745417/745417 [==============================] - 317s 425us/sample - loss: 1.3338 - val_loss: 1.2656\n",
      "Epoch 15/100\n",
      "745417/745417 [==============================] - 318s 426us/sample - loss: 1.3243 - val_loss: 1.2714\n",
      "Epoch 16/100\n",
      "745417/745417 [==============================] - 323s 434us/sample - loss: 1.3166 - val_loss: 1.2520\n",
      "Epoch 17/100\n",
      "745417/745417 [==============================] - 319s 428us/sample - loss: 1.3099 - val_loss: 1.2488\n",
      "Epoch 18/100\n",
      "745417/745417 [==============================] - 313s 420us/sample - loss: 1.3033 - val_loss: 1.2447\n",
      "Epoch 19/100\n",
      "745417/745417 [==============================] - 311s 417us/sample - loss: 1.2976 - val_loss: 1.2400\n",
      "Epoch 20/100\n",
      "745417/745417 [==============================] - 311s 417us/sample - loss: 1.2925 - val_loss: 1.2370\n",
      "Epoch 21/100\n",
      "745417/745417 [==============================] - 313s 420us/sample - loss: 1.2869 - val_loss: 1.2320\n",
      "Epoch 22/100\n",
      "745417/745417 [==============================] - 318s 427us/sample - loss: 1.2823 - val_loss: 1.2319\n",
      "Epoch 23/100\n",
      "745417/745417 [==============================] - 314s 421us/sample - loss: 1.2777 - val_loss: 1.2293\n",
      "Epoch 24/100\n",
      "745417/745417 [==============================] - 320s 429us/sample - loss: 1.2740 - val_loss: 1.2260\n",
      "Epoch 25/100\n",
      "745417/745417 [==============================] - 322s 432us/sample - loss: 1.2714 - val_loss: 1.2219\n",
      "Epoch 26/100\n",
      "745417/745417 [==============================] - 322s 432us/sample - loss: 1.2667 - val_loss: 1.2191\n",
      "Epoch 27/100\n",
      "745417/745417 [==============================] - 315s 422us/sample - loss: 1.2646 - val_loss: 1.2218\n",
      "Epoch 28/100\n",
      "745417/745417 [==============================] - 313s 420us/sample - loss: 1.2621 - val_loss: 1.2202\n",
      "Epoch 29/100\n",
      "745417/745417 [==============================] - 298s 400us/sample - loss: 1.2582 - val_loss: 1.2158\n",
      "Epoch 30/100\n",
      "745417/745417 [==============================] - 295s 396us/sample - loss: 1.2557 - val_loss: 1.2227\n",
      "Epoch 31/100\n",
      "745417/745417 [==============================] - 293s 392us/sample - loss: 1.2533 - val_loss: 1.2116\n",
      "Epoch 32/100\n",
      "745417/745417 [==============================] - 294s 394us/sample - loss: 1.2525 - val_loss: 1.2138\n",
      "Epoch 33/100\n",
      "745417/745417 [==============================] - 292s 391us/sample - loss: 1.2501 - val_loss: 1.2117\n",
      "Epoch 34/100\n",
      "745417/745417 [==============================] - 294s 394us/sample - loss: 1.2483 - val_loss: 1.2091\n",
      "Epoch 35/100\n",
      "745417/745417 [==============================] - 291s 390us/sample - loss: 1.2461 - val_loss: 1.2123\n",
      "Epoch 36/100\n",
      "745417/745417 [==============================] - 292s 391us/sample - loss: 1.2453 - val_loss: 1.2075\n",
      "Epoch 37/100\n",
      "745417/745417 [==============================] - 301s 404us/sample - loss: 1.2441 - val_loss: 1.2121\n",
      "Epoch 38/100\n",
      "745417/745417 [==============================] - 314s 422us/sample - loss: 1.2415 - val_loss: 1.2073\n",
      "Epoch 39/100\n",
      "745417/745417 [==============================] - 315s 423us/sample - loss: 1.2392 - val_loss: 1.2084\n",
      "Epoch 40/100\n",
      "745417/745417 [==============================] - 311s 418us/sample - loss: 1.2384 - val_loss: 1.2066\n",
      "Epoch 41/100\n",
      "745417/745417 [==============================] - 313s 420us/sample - loss: 1.2381 - val_loss: 1.2063\n",
      "Epoch 42/100\n",
      "745417/745417 [==============================] - 327s 439us/sample - loss: 1.2356 - val_loss: 1.2027\n",
      "Epoch 43/100\n",
      "745417/745417 [==============================] - 315s 422us/sample - loss: 1.2335 - val_loss: 1.2088\n",
      "Epoch 44/100\n",
      "745417/745417 [==============================] - 310s 416us/sample - loss: 1.2341 - val_loss: 1.2007\n",
      "Epoch 45/100\n",
      "745417/745417 [==============================] - 310s 416us/sample - loss: 1.2325 - val_loss: 1.2055\n",
      "Epoch 46/100\n",
      "745417/745417 [==============================] - 310s 416us/sample - loss: 1.2303 - val_loss: 1.2039\n",
      "Epoch 47/100\n",
      "745417/745417 [==============================] - 310s 415us/sample - loss: 1.2291 - val_loss: 1.2011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x280b6fafc48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model_save = ModelCheckpoint('models/trump_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=100, batch_size=128, callbacks=[early_stop, model_save], validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
